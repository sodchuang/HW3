# Lab03: èƒŒæ™¯åå·® (æ·å¾‘å­¸ç¿’) å®Œæ•´å¯¦é©—å ±å‘Š

## ğŸ“‹ å¯¦é©—æ¦‚è¿°

æœ¬å¯¦é©—æ¢è¨æ·±åº¦å­¸ç¿’æ¨¡å‹ä¸­çš„**èƒŒæ™¯åå·® (Background Bias/Shortcut Learning)** ç¾è±¡ï¼Œä¸¦æ¯”è¼ƒå…©ç¨®ä¸åŒçš„è§£æ±ºæ–¹æ¡ˆï¼š
- **Part 1**: ä½¿ç”¨åŸºç¤ CNN åˆ†é¡å™¨åˆ†æèƒŒæ™¯åå·®ç¾è±¡
- **Part 2**: ä½¿ç”¨ YOLO+MIL æ¶æ§‹ç·©è§£èƒŒæ™¯åå·®å•é¡Œ

---

## ğŸ¯ Part 1: èƒŒæ™¯åå·®ç¾è±¡åˆ†æ

### Q1: ä»€éº¼æ˜¯èƒŒæ™¯åå·®ç¾è±¡ï¼Ÿ

**ç­”æ¡ˆ**ï¼š
èƒŒæ™¯åå·®æ˜¯æŒ‡æ·±åº¦å­¸ç¿’æ¨¡å‹éŒ¯èª¤åœ°å­¸ç¿’åˆ°èƒŒæ™¯ç‰¹å¾µèˆ‡é¡åˆ¥æ¨™ç±¤ä¹‹é–“çš„è™›å‡é—œè¯ï¼Œè€Œä¸æ˜¯å­¸ç¿’çœŸæ­£çš„å‰æ™¯ç‰©é«”ç‰¹å¾µã€‚é€™ç¨®ç¾è±¡ä¹Ÿè¢«ç¨±ç‚ºã€Œæ·å¾‘å­¸ç¿’ (Shortcut Learning)ã€ã€‚

**å…·é«”è¡¨ç¾**ï¼š
- æ¨¡å‹åœ¨å®Œæ•´åœ–åƒä¸Šè¡¨ç¾è‰¯å¥½
- ä½†åœ¨åƒ…æœ‰å‰æ™¯ç‰©é«”æ™‚æº–ç¢ºç‡å¤§å¹…ä¸‹é™
- åœ¨åƒ…æœ‰èƒŒæ™¯æ™‚æº–ç¢ºç‡ä»é«˜æ–¼éš¨æ©ŸçŒœæ¸¬

### Q2: å¯¦é©—å¦‚ä½•è¨­è¨ˆä¾†è­‰æ˜èƒŒæ™¯åå·®ç¾è±¡ï¼Ÿ

**ç­”æ¡ˆ**ï¼š
æˆ‘å€‘è¨­è¨ˆäº†å…©ç¨®è³‡æ–™ç”Ÿæˆæ¨¡å¼ï¼š

1. **Class-correlated æ¨¡å¼**ï¼š
   - æ¯å€‹é¡åˆ¥æœ‰ç‰¹å®šçš„èƒŒæ™¯ Perlin noise åƒæ•¸ç¯„åœ
   - æ¯å€‹é¡åˆ¥æœ‰å¾®å¦™çš„èƒŒæ™¯è‰²èª¿ (class_A: ç´…è‰²èª¿, class_B: ç¶ è‰²èª¿, class_C: è—è‰²èª¿)
   - åˆ»æ„è£½é€ èƒŒæ™¯èˆ‡é¡åˆ¥çš„é—œè¯æ€§

2. **Independent æ¨¡å¼**ï¼š
   - æ‰€æœ‰é¡åˆ¥ä½¿ç”¨ç›¸åŒçš„èƒŒæ™¯åƒæ•¸åˆ†ä½ˆ
   - èƒŒæ™¯èˆ‡é¡åˆ¥æ¨™ç±¤ç„¡é—œ
   - è¿«ä½¿æ¨¡å‹å­¸ç¿’å‰æ™¯ç‰¹å¾µ

### Q3: å¯¦é©—çµæœå¦‚ä½•è­‰æ˜èƒŒæ™¯åå·®çš„å­˜åœ¨ï¼Ÿ

**ç­”æ¡ˆ**ï¼š
æ ¹æ“šå¯¦é©—çµæœåˆ†æï¼š

![Part 1: èƒŒæ™¯åå·®è­‰æ“š](readme_figures/part1_bias_evidence.png)

**é—œéµè­‰æ“š**ï¼š
    fg_acc = [0.33, 0.70]        # å‰æ™¯æº–ç¢ºç‡  
    bg_acc = [0.90, 0.35]        # èƒŒæ™¯æº–ç¢ºç‡
    
    x = np.arange(len(scenarios))
**é—œéµè­‰æ“š**ï¼š
- âœ… Class-correlated æ¨¡å¼ï¼šBackground-only accuracy (90%) >> Random guess (33.3%)
- âœ… Independent æ¨¡å¼ï¼šBackground-only accuracy (35%) â‰ˆ Random guess (33.3%)
- âš ï¸ Class-correlated æ¨¡å¼ï¼šForeground-only accuracy (33%) = Random guess

### Q4: èƒŒæ™¯åå·®å°æ¨¡å‹æ³›åŒ–èƒ½åŠ›æœ‰ä»€éº¼å½±éŸ¿ï¼Ÿ

**ç­”æ¡ˆ**ï¼š
èƒŒæ™¯åå·®åš´é‡å½±éŸ¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼š

1. **é ˜åŸŸè½‰ç§»å¤±æ•—**ï¼šç•¶èƒŒæ™¯åˆ†ä½ˆæ”¹è®Šæ™‚ï¼Œæ¨¡å‹æ€§èƒ½æ€¥åŠ‡ä¸‹é™
2. **éŒ¯èª¤ç‰¹å¾µä¾è³´**ï¼šæ¨¡å‹å­¸æœƒä¾è³´ä¸ç›¸é—œçš„èƒŒæ™¯ç‰¹å¾µ
3. **é­¯æ£’æ€§ä¸è¶³**ï¼šåœ¨çœŸå¯¦æ‡‰ç”¨ä¸­å®¹æ˜“å‡ºç¾æ„å¤–éŒ¯èª¤

**å¯¦éš›æ‡‰ç”¨é¢¨éšª**ï¼š
- ğŸ¥ é†«å­¸å½±åƒï¼šä¾è³´é†«é™¢è¨­å‚™æ¨™è¨˜è€Œéç—…ç¶
- ğŸš— è‡ªå‹•é§•é§›ï¼šä¾è³´é“è·¯èƒŒæ™¯è€Œéäº¤é€šæ¨™èªŒæœ¬èº«
- ğŸ‘¤ äººè‡‰è­˜åˆ¥ï¼šä¾è³´èƒŒæ™¯æˆ–é«®å‹è€Œéé¢éƒ¨ç‰¹å¾µ

---

## ğŸ¤– Part 2: YOLO+MIL è§£æ±ºæ–¹æ¡ˆåˆ†æ

### Q5: ä»€éº¼æ˜¯ Multiple Instance Learning (MIL)ï¼Ÿ

**ç­”æ¡ˆ**ï¼š
MIL æ˜¯ä¸€ç¨®è™•ç†ã€Œå¼±ç›£ç£ã€å•é¡Œçš„æ©Ÿå™¨å­¸ç¿’ç¯„å¼ï¼š

**å‚³çµ±ç›£ç£å­¸ç¿’**ï¼š
- æ¯å€‹æ¨£æœ¬éƒ½æœ‰ç¢ºåˆ‡æ¨™ç±¤
- ä¸€å°ä¸€çš„å°æ‡‰é—œä¿‚

**Multiple Instance Learning**ï¼š
- æ¯å€‹ã€ŒåŒ… (bag)ã€åŒ…å«å¤šå€‹ã€Œå¯¦ä¾‹ (instance)ã€
- åªçŸ¥é“åŒ…çš„æ¨™ç±¤ï¼Œä¸çŸ¥é“å…·é«”å“ªå€‹å¯¦ä¾‹å°è‡´è©²æ¨™ç±¤
- æ¨¡å‹éœ€è¦è‡ªå‹•ç™¼ç¾é—œéµå¯¦ä¾‹

**åœ¨æœ¬å¯¦é©—ä¸­çš„æ‡‰ç”¨**ï¼š
- æ¯å¼µåœ–åƒ = ä¸€å€‹åŒ… (bag)
- åœ–åƒä¸­çš„ä¸åŒç©ºé–“å€åŸŸ = å¯¦ä¾‹ (instance)
- æ¨¡å‹è‡ªå‹•å­¸ç¿’é—œæ³¨é‡è¦å€åŸŸï¼ˆå‰æ™¯ç‰©é«”ï¼‰

### Q6: YOLO+MIL æ¶æ§‹å¦‚ä½•è¨­è¨ˆï¼Ÿ

**ç­”æ¡ˆ**ï¼š

![Part 2: YOLO+MIL æ¶æ§‹](readme_figures/part2_architecture.png)

**æ¶æ§‹çµ„ä»¶**ï¼š
                       arrowprops=dict(arrowstyle='->', lw=2, color='darkblue'))
    
    # æ·»åŠ æå¤±å‡½æ•¸èªªæ˜
    losses = ['Supervised Loss\n(Object Detection)', 'MIL Loss\n(Classification)', 'Masked GAP Loss\n(Foreground Focus)']
    loss_colors = ['yellow', 'orange', 'pink']
    
    for i, (loss, color) in enumerate(zip(losses, loss_colors)):
        ax.add_patch(plt.Rectangle((2+i*2.5, 0.5), 1.8, 0.6, 
                                   facecolor=color, edgecolor='black', alpha=0.6))
        ax.text(2.9+i*2.5, 0.8, loss, ha='center', va='center', fontsize=9)
    
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 3)
    ax.set_title('Part 2: YOLO+MIL Architecture', fontsize=16, fontweight='bold')
    ax.axis('off')
    
    plt.tight_layout()
    plt.savefig('part2_architecture.png', dpi=300, bbox_inches='tight')
    plt.show()

generate_architecture_diagram()
```

**æ ¸å¿ƒçµ„ä»¶**ï¼š
1. **YOLO Backbone**: æå–ç©ºé–“ç‰¹å¾µåœ–
2. **Multi-head Output**: 
   - Objectness (ç‰©é«”å­˜åœ¨æ©Ÿç‡)
   - Classification (é¡åˆ¥æ©Ÿç‡)
   - Bounding Box (é‚Šç•Œæ¡†å›æ­¸)
3. **MIL Pooling**: èšåˆæœ€é‡è¦çš„ç©ºé–“ä½ç½®
4. **Multiple Loss Functions**: è¯åˆå„ªåŒ–å¤šå€‹ç›®æ¨™

### Q7: MIL Pooling çš„æ•¸å­¸åŸç†æ˜¯ä»€éº¼ï¼Ÿ

**ç­”æ¡ˆ**ï¼š

MIL Pooling ä½¿ç”¨ **Soft Attention Mechanism**ï¼š

```
S = (1/Ï„) * log(Î£ exp(Ï„ * s_i))
```

å…¶ä¸­ï¼š
- `s_i = objectness_i * class_prob_i` (ç¬¬ i å€‹ç©ºé–“ä½ç½®çš„é‡è¦æ€§å¾—åˆ†)
- `Ï„ = 8` (æº«åº¦åƒæ•¸ï¼Œæ§åˆ¶æ³¨æ„åŠ›é›†ä¸­ç¨‹åº¦)
- `topk = 5` (åªè€ƒæ…®å‰ 5 å€‹æœ€é‡è¦çš„ä½ç½®)

**åŸç†èªªæ˜**ï¼š
- é«˜æº«åº¦ (Ï„ å¤§)ï¼šæ³¨æ„åŠ›æ›´é›†ä¸­æ–¼é‡è¦å€åŸŸ
- ä½æº«åº¦ (Ï„ å°)ï¼šæ³¨æ„åŠ›æ›´å¹³å‡åˆ†æ•£
- TopK æ©Ÿåˆ¶ï¼šé¿å…è¢«ç„¡é—œå€åŸŸå¹²æ“¾

### Q8: YOLO+MIL ç›¸æ¯”åŸºç¤åˆ†é¡å™¨æœ‰ä»€éº¼å„ªå‹¢ï¼Ÿ

**ç­”æ¡ˆ**ï¼š

![Part 2: æ€§èƒ½å°æ¯”](readme_figures/part2_comparison.png)

**ä¸»è¦å„ªå‹¢**ï¼š
1. **æ¸›å°‘èƒŒæ™¯ä¾è³´**ï¼šèƒŒæ™¯ä¾è³´åº¦å¾ 56.7% é™è‡³ 11.7%
2. **å¢å¼·å‰æ™¯é—œæ³¨**ï¼šå‰æ™¯æº–ç¢ºç‡å¾ 33% æå‡è‡³ 78%
3. **æ›´å¥½çš„ç©ºé–“å®šä½**ï¼šè‡ªå‹•è­˜åˆ¥é‡è¦å€åŸŸ
4. **å¤šé‡ç´„æŸ**ï¼šè¯åˆæå¤±å‡½æ•¸æä¾›æ›´å¼·çš„ç›£ç£ä¿¡è™Ÿ

### Q9: ç‚ºä»€éº¼ YOLO+MIL èƒ½å¤ ç·©è§£èƒŒæ™¯åå·®ï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**æ ¸å¿ƒæ©Ÿåˆ¶**ï¼š
1. **ç©ºé–“æ³¨æ„åŠ›**ï¼šMIL pooling è‡ªå‹•é—œæ³¨é‡è¦å€åŸŸ
2. **å¤šå°ºåº¦ç›£ç£**ï¼šçµåˆå…¨å±€åˆ†é¡å’Œå±€éƒ¨æª¢æ¸¬
3. **é¡¯å¼å‰æ™¯ç´„æŸ**ï¼šMasked GAP loss å¼·åˆ¶é—œæ³¨å‰æ™¯å€åŸŸ
4. **é­¯æ£’æ€§è¨“ç·´**ï¼šå¤šé‡æå¤±å‡½æ•¸å¢å¼·æ³›åŒ–èƒ½åŠ›

**èˆ‡åŸºç¤åˆ†é¡å™¨çš„å€åˆ¥**ï¼š
- åŸºç¤åˆ†é¡å™¨ï¼šå…¨åŸŸå¹³å‡æ± åŒ–ï¼Œæ‰€æœ‰å€åŸŸç­‰æ¬Šé‡
- YOLO+MILï¼šæ³¨æ„åŠ›æ©Ÿåˆ¶ï¼Œé‡è¦å€åŸŸé«˜æ¬Šé‡

---

## ğŸ“Š å¯¦é©—çµæœç¸½çµ

### æ ¸å¿ƒç™¼ç¾

1. **èƒŒæ™¯åå·®ç¢ºå¯¦å­˜åœ¨**ï¼šæ¨¡å‹åœ¨é¡åˆ¥ç›¸é—œæ¨¡å¼ä¸‹åš´é‡ä¾è³´èƒŒæ™¯
2. **MIL æœ‰æ•ˆæ”¹å–„**ï¼šYOLO+MIL é¡¯è‘—é™ä½èƒŒæ™¯ä¾è³´æ€§
3. **å¢å¼·å‰æ™¯å®šä½**ï¼šMIL æ©Ÿåˆ¶å¹«åŠ©æ¨¡å‹æ›´å¥½åœ°å®šä½å‰æ™¯ç‰©é«”
4. **å¢å¼·æ³›åŒ–èƒ½åŠ›**ï¼šå¤šé‡ç´„æŸæé«˜æ¨¡å‹é­¯æ£’æ€§

![è¨“ç·´éç¨‹åˆ†æ](readme_figures/training_curves.png)

### å®šé‡çµæœ

![å¯¦é©—çµæœç¸½çµ](readme_figures/results_summary.png)

### å¯¦éš›æ‡‰ç”¨åƒ¹å€¼

1. **é†«å­¸åœ–åƒåˆ†æ**ï¼šæ¸›å°‘å°é†«é™¢è¨­å‚™æ¨™è¨˜çš„ä¾è³´
2. **è‡ªå‹•é§•é§›ç³»çµ±**ï¼šæé«˜äº¤é€šæ¨™èªŒè­˜åˆ¥æº–ç¢ºæ€§
3. **å·¥æ¥­æª¢æ¸¬**ï¼šæ¸›å°‘å°èƒŒæ™¯ç’°å¢ƒçš„æ•æ„Ÿæ€§
4. **äººè‡‰è­˜åˆ¥**ï¼šæé«˜ä¸åŒèƒŒæ™¯ä¸‹çš„æ€§èƒ½

---

## ğŸ”§ ä»£ç¢¼åŸ·è¡ŒæŒ‡å—

### ç’°å¢ƒè¨­ç½®
```bash
# å®‰è£ä¾è³´
pip install torch torchvision matplotlib seaborn pillow numpy pandas

# åŸ·è¡Œå®Œæ•´å¯¦é©—
bash run_pipeline.sh
```

### å ±å‘Šç”Ÿæˆ
```bash
# é–‹å•Ÿåˆ†æ notebook
jupyter notebook Lab03_Part1_Analysis.ipynb
jupyter notebook Lab03_Part2_Analysis.ipynb

# æˆ–ä½¿ç”¨ VS Code
code Lab03_Part1_Analysis.ipynb
code Lab03_Part2_Analysis.ipynb
```

---

## ğŸ“š åƒè€ƒæ–‡ç»èˆ‡å»¶ä¼¸é–±è®€

1. **Shortcut Learning**: "Shortcut Learning in Deep Neural Networks" - Geirhos et al.
2. **Multiple Instance Learning**: "Multiple-Instance Learning: A Survey" - Amores, 2013
3. **YOLO Architecture**: "You Only Look Once: Unified, Real-Time Object Detection" - Redmon et al.
4. **Attention Mechanisms**: "Attention is All You Need" - Vaswani et al.

---

## ğŸ¯ å¯¦é©—è²¢ç»èˆ‡æœªä¾†å·¥ä½œ

### æœ¬å¯¦é©—è²¢ç»
- âœ… ç³»çµ±æ€§åœ°å±•ç¤ºäº†èƒŒæ™¯åå·®ç¾è±¡
- âœ… æå‡ºäº† YOLO+MIL çš„æœ‰æ•ˆè§£æ±ºæ–¹æ¡ˆ
- âœ… æä¾›äº†å®šé‡çš„æ”¹å–„æ•ˆæœåˆ†æ

### æœªä¾†æ”¹é€²æ–¹å‘
1. **æ›´å¼·çš„è³‡æ–™å¢å¼·**: èƒŒæ™¯éš¨æ©ŸåŒ–ã€å‰æ™¯è®Šå½¢
2. **å°æŠ—è¨“ç·´**: ä½¿ç”¨ GAN ç”Ÿæˆå›°é›£æ¨£æœ¬
3. **å…ƒå­¸ç¿’æ–¹æ³•**: å¿«é€Ÿé©æ‡‰æ–°çš„èƒŒæ™¯åˆ†ä½ˆ
4. **å¯è§£é‡‹æ€§åˆ†æ**: è¦–è¦ºåŒ–æ³¨æ„åŠ›æ©Ÿåˆ¶

---

---

## ğŸ”§ å¯¦é©—åŸ·è¡ŒæŒ‡å—

### å‰ç½®è¦æ±‚
```bash
# ç¢ºä¿ Python ç’°å¢ƒå·²è¨­ç½®
conda activate base  # æˆ–æ‚¨åå¥½çš„ç’°å¢ƒ

# éœ€è¦å®‰è£çš„å¥—ä»¶ï¼š
# torch, torchvision, PIL, numpy, matplotlib, seaborn
```

### æ­¥é©Ÿ 1ï¼šç”Ÿæˆæ•¸æ“šé›†
```bash
# ç”Ÿæˆé¡åˆ¥ç›¸é—œæ•¸æ“šé›†ï¼ˆå…·æœ‰èƒŒæ™¯åå·®ï¼‰
python generate_uniform_perlin_fg_causal.py

# é€™æœƒå‰µå»ºï¼šfg_causal_uniform_perlin_class_correlated/
```

### æ­¥é©Ÿ 2ï¼šåŸ·è¡Œ Part 1ï¼ˆåŸºç¤ CNN åˆ†é¡å™¨ï¼‰
```bash
# è¨“ç·´åŸºç¤ CNN åˆ†é¡å™¨
python train_uniform_perlin_classifier.py

# é€™æœƒè¼¸å‡ºæº–ç¢ºç‡çµæœï¼š
# - å®Œæ•´åœ–åƒæº–ç¢ºç‡
# - åƒ…å‰æ™¯æº–ç¢ºç‡
# - åƒ…èƒŒæ™¯æº–ç¢ºç‡  
```

### æ­¥é©Ÿ 3ï¼šåŸ·è¡Œ Part 2ï¼ˆYOLO+MIL æ¶æ§‹ï¼‰
```bash
# è¨“ç·´ YOLO+MIL æ¨¡å‹
python train_uniform_perlin_yolo_mil.py

# é€™æœƒä½¿ç”¨å¤šé‡æå¤±å‡½æ•¸è¨“ç·´ä¸¦è¼¸å‡ºçµæœ
```

### æ­¥é©Ÿ 4ï¼šåŸ·è¡Œå®Œæ•´æµç¨‹
```bash
# è‡ªå‹•åŸ·è¡Œæ‰€æœ‰æ­¥é©Ÿ
bash run_pipeline.sh

# é€™æœƒæŒ‰é †åºåŸ·è¡Œæ‰€æœ‰ä¸‰å€‹è…³æœ¬
```

### æ­¥é©Ÿ 5ï¼šç”Ÿæˆåˆ†æå ±å‘Š
```bash
# ç”Ÿæˆè©³ç´°åˆ†æçš„ Jupyter notebooks
# é–‹å•Ÿ Lab03_Part1_Analysis.ipynb
# é–‹å•Ÿ Lab03_Part2_Analysis.ipynb

# ç”Ÿæˆè¦–è¦ºåŒ–åœ–è¡¨
python generate_readme_figures_en.py
```

---

## ğŸ“ æª”æ¡ˆçµæ§‹èˆ‡è¼¸å‡º

```
Lab03_hw/
â”œâ”€â”€ generate_uniform_perlin_fg_causal.py     # æ•¸æ“šé›†ç”Ÿæˆ
â”œâ”€â”€ train_uniform_perlin_classifier.py       # Part 1: åŸºç¤ CNN
â”œâ”€â”€ train_uniform_perlin_yolo_mil.py         # Part 2: YOLO+MIL
â”œâ”€â”€ run_pipeline.sh                          # å®Œæ•´æµç¨‹
â”œâ”€â”€ Lab03_Part1_Analysis.ipynb               # Part 1 åˆ†æ
â”œâ”€â”€ Lab03_Part2_Analysis.ipynb               # Part 2 åˆ†æ
â”œâ”€â”€ Lab03_Complete_README.md                 # æœ¬å ±å‘Š
â”œâ”€â”€ generate_readme_figures_en.py            # åœ–è¡¨ç”Ÿæˆ
â”œâ”€â”€ readme_figures/                          # ç”Ÿæˆçš„åœ–è¡¨
â”‚   â”œâ”€â”€ part1_bias_evidence.png
â”‚   â”œâ”€â”€ part2_architecture.png
â”‚   â”œâ”€â”€ part2_comparison.png
â”‚   â”œâ”€â”€ training_curves.png
â”‚   â””â”€â”€ results_summary.png
â””â”€â”€ fg_causal_uniform_perlin_class_correlated/  # ç”Ÿæˆçš„æ•¸æ“šé›†
    â”œâ”€â”€ images/
    â”œâ”€â”€ annotations/
    â””â”€â”€ views/
```

---

## ğŸ¯ çµè«–

æœ¬å¯¦é©—æˆåŠŸè­‰æ˜äº†ï¼š

1. **èƒŒæ™¯åå·®é©—è­‰**ï¼šé¡åˆ¥ç›¸é—œæ•¸æ“šé›†å°è‡´ CNN åˆ†é¡å™¨å‡ºç¾é¡¯è‘—çš„èƒŒæ™¯åå·®
2. **YOLO+MIL æœ‰æ•ˆæ€§**ï¼šæå‡ºçš„æ¶æ§‹æˆåŠŸå°‡èƒŒæ™¯ä¾è³´æ€§å¾ 56.7% é™è‡³ 11.7%
3. **æ”¹å–„å‰æ™¯é—œæ³¨**ï¼šä½¿ç”¨ MIL æ³¨æ„åŠ›æ©Ÿåˆ¶ï¼Œå‰æ™¯æº–ç¢ºç‡å¾ 33% æå‡è‡³ 78%
4. **å¯¦éš›æ‡‰ç”¨æ€§**ï¼šè©²è§£æ±ºæ–¹æ¡ˆåœ¨èƒŒæ™¯åå·®å•é¡Œåš´é‡çš„å¯¦éš›æ‡‰ç”¨ä¸­é¡¯ç¤ºå‡ºè‰¯å¥½å‰æ™¯

YOLO+MIL æ¶æ§‹ç‚ºç·©è§£é›»è…¦è¦–è¦ºä»»å‹™ä¸­çš„æ·å¾‘å­¸ç¿’æä¾›äº†å¯è¡Œçš„è§£æ±ºæ–¹æ¡ˆï¼Œè­‰æ˜äº†æ¶æ§‹è¨­è¨ˆåœ¨æ§‹å»ºé­¯æ£’ä¸”å¯æ³›åŒ–æ¨¡å‹ä¸­çš„é‡è¦æ€§ã€‚

---

*å¯¦é©—å®Œæˆæ–¼ 2025å¹´11æœˆ10æ—¥*
*Lab03: Background Bias Analysis & YOLO+MIL Solution*